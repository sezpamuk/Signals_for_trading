# === Imports ===
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import MinMaxScaler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.backend as K
from skopt import gp_minimize
from skopt.space import Integer, Real
from skopt.utils import use_named_args

# === Simulate Trading Book Data ===
np.random.seed(42)
dates = pd.date_range(start='2022-01-01', periods=300)
df_original = pd.DataFrame({
    'pnl': np.random.normal(0, 0.5, size=300),
    'cds_level': 100 + np.cumsum(np.random.normal(0, 0.5, size=300)),
    'cs01': np.random.uniform(0.5, 1.5, size=300),
}, index=dates)

# === Define Search Space for Optimization ===
space = [
    Integer(1, 10, name='return_horizon'),
    Integer(10, 60, name='corr_window'),
    Integer(10, 40, name='lookback'),
    Real(0.1, 0.9, name='hedge_threshold')
]

@use_named_args(space)
def objective(return_horizon, corr_window, lookback, hedge_threshold):
    df = df_original.copy()
    df['cds_change'] = df['cds_level'].diff(periods=return_horizon)
    df['abs_cds_change'] = df['cds_change'].abs()
    df.dropna(inplace=True)
    df['rolling_corr'] = df['pnl'].rolling(window=corr_window).corr(df['cds_change'])
    df.dropna(inplace=True)

    if len(df) < lookback + 50:
        return 1e6

    df['ideal_scaler'] = -df['pnl'] / (df['cs01'] * df['abs_cds_change'])
    df['ideal_scaler'] = df['ideal_scaler'].clip(0, 1)

    features = ['pnl', 'cds_change', 'cs01', 'rolling_corr']
    scaler_X = MinMaxScaler()
    X_scaled = scaler_X.fit_transform(df[features])
    y = df['ideal_scaler'].values

    X_seq, y_seq = [], []
    for i in range(lookback, len(X_scaled)):
        X_seq.append(X_scaled[i-lookback:i])
        y_seq.append(y[i])
    X_seq, y_seq = np.array(X_seq), np.array(y_seq)

    if len(X_seq) < 50:
        return 1e6

    K.clear_session()
    model = Sequential()
    model.add(LSTM(32, input_shape=(lookback, X_seq.shape[2])))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(0.001), loss='mse')
    model.fit(X_seq, y_seq, epochs=10, batch_size=32, verbose=0, validation_split=0.2, shuffle=False)

    preds = model.predict(X_seq).flatten()
    df_eval = df.iloc[lookback:].copy()
    df_eval['hedge_scaler_raw'] = preds
    df_eval['apply_hedge'] = (df_eval['hedge_scaler_raw'] >= hedge_threshold).astype(int)
    df_eval['hedge_scaler'] = df_eval['apply_hedge'] * df_eval['hedge_scaler_raw']
    df_eval['hedge_notional'] = df_eval['hedge_scaler'] * df_eval['cs01']
    df_eval['hedge_notional'] = df_eval['hedge_notional'].clip(upper=0.1)
    df_eval['hedge_pnl'] = df_eval['hedge_notional'] * df_eval['abs_cds_change']
    df_eval['total_pnl'] = df_eval['pnl'] + df_eval['hedge_pnl']

    hedge_loss_penalty = (df_eval['total_pnl'] < df_eval['pnl']).sum() * 0.1
    return -df_eval['total_pnl'].sum() + hedge_loss_penalty

# === Run Optimization ===
res = gp_minimize(objective, space, n_calls=20, random_state=42)
best_params = {
    "return_horizon": res.x[0],
    "corr_window": res.x[1],
    "lookback": res.x[2],
    "hedge_threshold": res.x[3],
    "maximized_total_pnl": -res.fun
}
print("âœ… Best Parameters:", best_params)

# === Final Model Evaluation & Visualization ===
def final_lstm_evaluation(params):
    df = df_original.copy()
    df['cds_change'] = df['cds_level'].diff(periods=params['return_horizon'])
    df['abs_cds_change'] = df['cds_change'].abs()
    df.dropna(inplace=True)
    df['rolling_corr'] = df['pnl'].rolling(window=params['corr_window']).corr(df['cds_change'])
    df.dropna(inplace=True)

    df['ideal_scaler'] = -df['pnl'] / (df['cs01'] * df['abs_cds_change'])
    df['ideal_scaler'] = df['ideal_scaler'].clip(0, 1)

    features = ['pnl', 'cds_change', 'cs01', 'rolling_corr']
    scaler_X = MinMaxScaler()
    X_scaled = scaler_X.fit_transform(df[features])
    y = df['ideal_scaler'].values

    X_seq, y_seq = [], []
    for i in range(params['lookback'], len(X_scaled)):
        X_seq.append(X_scaled[i - params['lookback']:i])
        y_seq.append(y[i])
    X_seq, y_seq = np.array(X_seq), np.array(y_seq)

    K.clear_session()
    model = Sequential()
    model.add(LSTM(32, input_shape=(params['lookback'], X_seq.shape[2])))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(optimizer=Adam(0.001), loss='mse')
    model.fit(X_seq, y_seq, epochs=10, batch_size=32, verbose=0, validation_split=0.2, shuffle=False)

    preds = model.predict(X_seq).flatten()
    df_eval = df.iloc[params['lookback']:].copy()
    df_eval['hedge_scaler_raw'] = preds
    df_eval['apply_hedge'] = (df_eval['hedge_scaler_raw'] >= params['hedge_threshold']).astype(int)
    df_eval['hedge_scaler'] = df_eval['apply_hedge'] * df_eval['hedge_scaler_raw']
    df_eval['hedge_notional'] = df_eval['hedge_scaler'] * df_eval['cs01']
    df_eval['hedge_notional'] = df_eval['hedge_notional'].clip(upper=0.1)
    df_eval['hedge_pnl'] = df_eval['hedge_notional'] * df_eval['abs_cds_change']
    df_eval['total_pnl'] = df_eval['pnl'] + df_eval['hedge_pnl']

    # ðŸ“ˆ Plot Cumulative PnL
    plt.figure(figsize=(12, 6))
    plt.plot(df_eval.index, df_eval['pnl'].cumsum(), label='Unhedged PnL', linestyle='--')
    plt.plot(df_eval.index, df_eval['total_pnl'].cumsum(), label='Hedged PnL', linewidth=2)
    plt.title('Cumulative PnL: Before and After Hedging')
    plt.xlabel('Date')
    plt.ylabel('Cumulative PnL (in Millions)')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.show()

    return df_eval

# === Run Final Evaluation ===
final_results = final_lstm_evaluation(best_params)