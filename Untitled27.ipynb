{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf5124d-7071-4dfd-bca8-686afe35222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import streamlit as st\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from xbbg import blp\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 1: Config and Setup\n",
    "# ----------------------------------\n",
    "\n",
    "TICKERS = {\n",
    "    'CDX IG': 'CDX IG CDSI GEN 5Y Corp',\n",
    "    'CDX HY': 'CDX HY CDSI GEN 5Y Corp',\n",
    "    'iTraxx Main': 'ITRAXX EUR CDSI GEN 5Y Corp',\n",
    "    'iTraxx Xover': 'ITRAXX XOVER CDSI GEN 5Y Corp'\n",
    "}\n",
    "\n",
    "COUPON_RATES = {\n",
    "    'CDX IG': 100,    # 100 bps\n",
    "    'CDX HY': 500,    # 500 bps\n",
    "    'iTraxx Main': 100,  # 100 bps\n",
    "    'iTraxx Xover': 500  # 500 bps\n",
    "}\n",
    "\n",
    "CS01_LIMITS = {\n",
    "    'CDX IG': 250000,\n",
    "    'CDX HY': 100000,\n",
    "    'iTraxx Main': 250000,\n",
    "    'iTraxx Xover': 100000\n",
    "}\n",
    "\n",
    "NOTIONAL = 10_000_000\n",
    "START_DATE = '2023-01-01'\n",
    "END_DATE = pd.Timestamp.today().strftime('%Y-%m-%d')\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 2: Data Loading\n",
    "# ----------------------------------\n",
    "\n",
    "def load_data(pnl_file):\n",
    "    # Load PNL data from CSV\n",
    "    pnl_data = pd.read_csv(pnl_file, parse_dates=['date'])\n",
    "    pnl_data = pnl_data.set_index('date')\n",
    "    \n",
    "    # Resample daily PNL to weekly\n",
    "    weekly_pnl = pnl_data.resample('W-FRI').sum()\n",
    "    \n",
    "    # Fetch CDS data from Bloomberg\n",
    "    cds_data = fetch_cds_data(TICKERS, START_DATE, END_DATE)\n",
    "    \n",
    "    # Align dates between PNL and CDS data\n",
    "    aligned_data = pd.concat([weekly_pnl, cds_data], axis=1).dropna()\n",
    "    return aligned_data.iloc[:, 0], aligned_data.iloc[:, 1:]\n",
    "\n",
    "def fetch_cds_data(tickers, start_date, end_date):\n",
    "    data = pd.DataFrame()\n",
    "    for name, bbg_ticker in tickers.items():\n",
    "        try:\n",
    "            df = blp.bdh(bbg_ticker, 'PX_LAST', start_date, end_date, Per='W')\n",
    "            df = df.rename(columns={'PX_LAST': name})\n",
    "            data = pd.concat([data, df], axis=1)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to fetch {bbg_ticker}: {e}\")\n",
    "    return data.dropna()\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 3: Modeling & Optimization\n",
    "# ----------------------------------\n",
    "\n",
    "def calculate_cs01(spread, notional, duration=5):\n",
    "    return notional * duration * 0.0001\n",
    "\n",
    "def train_pnl_model(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_signal_model(features, pnl):\n",
    "    label = (pnl > 0).astype(int)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(features, label)\n",
    "    return model\n",
    "\n",
    "def optimize_hedge(expected_pnl, spreads, cs01_values, cs01_limits, tickers):\n",
    "    # Calculate weekly costs (roll + coupon)\n",
    "    weekly_roll_cost = 0.2 * spreads.values * NOTIONAL / 52 * 0.0001\n",
    "    weekly_coupon_cost = np.array([COUPON_RATES[t] * NOTIONAL * 1/52 * 0.0001 for t in tickers])\n",
    "    total_weekly_cost = weekly_roll_cost + weekly_coupon_cost\n",
    "\n",
    "    def objective(weights):\n",
    "        return -np.dot(weights, expected_pnl - total_weekly_cost)\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': lambda w, i=i: cs01_limits[i] - w[i] * cs01_values[i]} \n",
    "                 for i in range(len(expected_pnl))]\n",
    "    bounds = [(0, None) for _ in expected_pnl]\n",
    "    initial_guess = np.zeros(len(expected_pnl))\n",
    "\n",
    "    result = minimize(objective, initial_guess, bounds=bounds, constraints=constraints)\n",
    "    return result.x if result.success else np.zeros(len(expected_pnl))\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 4: Backtesting\n",
    "# ----------------------------------\n",
    "\n",
    "def backtest_strategy(signals, hedge_pnl_df, desk_pnl, max_hold_weeks=10):\n",
    "    position = 0\n",
    "    entry_idx = -1\n",
    "    pnl_history = []\n",
    "    cum_hedged = []\n",
    "    cum_unhedged = []\n",
    "    open_pnl = 0\n",
    "\n",
    "    for i in range(len(signals)):\n",
    "        signal = signals.iloc[i]\n",
    "        date = signals.index[i]\n",
    "\n",
    "        if position == 0 and signal == 1:\n",
    "            position = 1\n",
    "            entry_idx = i\n",
    "            open_pnl = 0\n",
    "        elif position == 1:\n",
    "            holding_period = i - entry_idx\n",
    "            if signal == 0 or holding_period > max_hold_weeks or (open_pnl < -50000):\n",
    "                position = 0\n",
    "                entry_idx = -1\n",
    "                open_pnl = 0\n",
    "\n",
    "        hedge_val = hedge_pnl_df.iloc[i].sum() if position else 0\n",
    "        total_pnl = desk_pnl.iloc[i] + hedge_val\n",
    "        open_pnl += hedge_val\n",
    "        pnl_history.append(total_pnl)\n",
    "\n",
    "        cum_hedged.append(sum(pnl_history))\n",
    "        cum_unhedged.append(desk_pnl.iloc[:i + 1].sum())\n",
    "\n",
    "    return pd.Series(cum_unhedged, index=signals.index), pd.Series(cum_hedged, index=signals.index), pnl_history\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 5: Run Model\n",
    "# ----------------------------------\n",
    "\n",
    "def run_model(pnl_file):\n",
    "    desk_pnl, cds_data = load_data(pnl_file)\n",
    "    features = cds_data.pct_change().dropna()\n",
    "    desk_pnl = desk_pnl[features.index]  # Align dates\n",
    "    \n",
    "    pnl_model = train_pnl_model(features, desk_pnl)\n",
    "    predicted_pnl = pd.Series(pnl_model.predict(features), index=features.index)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for r in [1, 2]:\n",
    "        for combo in combinations(TICKERS.keys(), r):\n",
    "            sub_features = features[list(combo)]\n",
    "            hedge_pnl = -sub_features * NOTIONAL * 0.5\n",
    "            avg_hedge_pnl = hedge_pnl.mean().values\n",
    "            latest_spreads = cds_data.iloc[-1][list(combo)]\n",
    "            cs01_vals = [calculate_cs01(latest_spreads[t], NOTIONAL) for t in combo]\n",
    "            cs01_lims = [CS01_LIMITS[t] for t in combo]\n",
    "            weights = optimize_hedge(avg_hedge_pnl, latest_spreads, cs01_vals, cs01_lims, combo)\n",
    "            \n",
    "            # Calculate costs with corrected formula\n",
    "            roll_cost = 0.2 * latest_spreads.values * NOTIONAL / 52 * 0.0001\n",
    "            coupon_cost = np.array([COUPON_RATES[t] * NOTIONAL * 1/52 * 0.0001 for t in combo])\n",
    "            total_cost = roll_cost + coupon_cost\n",
    "            \n",
    "            net_pnl = predicted_pnl + hedge_pnl @ weights - (weights @ total_cost)\n",
    "            sharpe = net_pnl.mean() / net_pnl.std()\n",
    "\n",
    "            results.append({\n",
    "                'combo': combo,\n",
    "                'weights': weights,\n",
    "                'net_pnl': net_pnl,\n",
    "                'sharpe': sharpe,\n",
    "                'hedge_pnl': hedge_pnl @ weights,\n",
    "                'full_hedge_pnl': hedge_pnl\n",
    "            })\n",
    "\n",
    "    best = max(results, key=lambda x: x['sharpe'])\n",
    "    signal_model = train_signal_model(features[list(best['combo'])], best['net_pnl'])\n",
    "    predicted_signals = pd.Series(signal_model.predict(features[list(best['combo'])]), index=features.index)\n",
    "\n",
    "    return {\n",
    "        'combo': best['combo'],\n",
    "        'weights': best['weights'],\n",
    "        'net_pnl': best['net_pnl'],\n",
    "        'signals': predicted_signals,\n",
    "        'features': features[list(best['combo'])],\n",
    "        'hedge_pnl': best['hedge_pnl'],\n",
    "        'desk_pnl': desk_pnl,\n",
    "        'full_hedge_pnl': best['full_hedge_pnl']\n",
    "    }\n",
    "\n",
    "# ----------------------------------\n",
    "# Step 6: Streamlit Dashboard\n",
    "# ----------------------------------\n",
    "\n",
    "def display_dashboard(results):\n",
    "    st.set_page_config(layout=\"wide\")\n",
    "    st.title(\"📊 CDS Hedging Dashboard with Backtest\")\n",
    "\n",
    "    combo = results['combo']\n",
    "    weights = results['weights']\n",
    "    net_pnl = results['net_pnl']\n",
    "    signals = results['signals']\n",
    "    hedge_notional = pd.Series(weights * NOTIONAL, index=combo)\n",
    "\n",
    "    st.markdown(f\"\"\"\n",
    "    ### 🔎 Best Hedge Instruments:\n",
    "    - **{' and '.join(combo)}**\n",
    "    - Optimal Weights: {weights}\n",
    "    - Notional Amounts: {hedge_notional.to_dict()}\n",
    "    \"\"\")\n",
    "\n",
    "    st.markdown(\"\"\"\n",
    "    ### 💰 Cost Structure\n",
    "    - **Roll Cost**: 20% of spread annually (weekly: 0.2 * spread * notional / 52 * 0.0001)\n",
    "    - **Coupon Cost**: \n",
    "      - IG/Main: 100bps (weekly: 100 * notional / 52 * 0.0001)\n",
    "      - HY/Xover: 500bps (weekly: 500 * notional / 52 * 0.0001)\n",
    "    \"\"\")\n",
    "\n",
    "    st.subheader(\"📈 Net PnL Over Time\")\n",
    "    st.line_chart(net_pnl.rename(\"Net PnL\"))\n",
    "\n",
    "    st.subheader(\"📏 Hedge Notional Bar Chart\")\n",
    "    st.bar_chart(hedge_notional.rename(\"Notional\"))\n",
    "\n",
    "    st.subheader(\"🛎️ Weekly Hedge Trade Signals\")\n",
    "    signal_df = pd.DataFrame({\n",
    "        \"Date\": net_pnl.index,\n",
    "        \"Signal\": signals.replace({1: \"BUY\", 0: \"HOLD\"}),\n",
    "        \"Net PnL\": net_pnl.values\n",
    "    }).set_index(\"Date\")\n",
    "    st.dataframe(signal_df.style.highlight_max(axis=0))\n",
    "\n",
    "    st.subheader(\"🔬 Feature Correlation Heatmap\")\n",
    "    corr = results['features'].corr()\n",
    "    fig, ax = plt.subplots()\n",
    "    sns.heatmap(corr, annot=True, cmap='coolwarm', ax=ax)\n",
    "    st.pyplot(fig)\n",
    "\n",
    "    st.subheader(\"🔁 Strategy Backtest\")\n",
    "\n",
    "    cum_unhedged, cum_hedged, hedged_pnl = backtest_strategy(\n",
    "        results['signals'],\n",
    "        results['full_hedge_pnl'],\n",
    "        results['desk_pnl']\n",
    "    )\n",
    "\n",
    "    chart_df = pd.DataFrame({\n",
    "        'Unhedged Cumulative PnL': cum_unhedged,\n",
    "        'Hedged Cumulative PnL': cum_hedged\n",
    "    })\n",
    "    st.line_chart(chart_df)\n",
    "\n",
    "    st.markdown(f\"\"\"\n",
    "    **Backtest Summary**\n",
    "    - Total Unhedged PnL: ${cum_unhedged.iloc[-1]:,.0f}\n",
    "    - Total Hedged PnL: ${cum_hedged.iloc[-1]:,.0f}\n",
    "    - Strategy Gain: ${cum_hedged.iloc[-1] - cum_unhedged.iloc[-1]:,.0f}\n",
    "    \"\"\")\n",
    "\n",
    "# ----------------------------------\n",
    "# MAIN RUN\n",
    "# ----------------------------------\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Add file uploader for PNL CSV\n",
    "    st.sidebar.title(\"PNL Data Upload\")\n",
    "    pnl_file = st.sidebar.file_uploader(\"Upload your PNL CSV file\", type=[\"csv\"])\n",
    "    \n",
    "    if pnl_file is not None:\n",
    "        try:\n",
    "            results = run_model(pnl_file)\n",
    "            display_dashboard(results)\n",
    "        except Exception as e:\n",
    "            st.error(f\"Error processing file: {str(e)}\")\n",
    "    else:\n",
    "        st.info(\"Please upload a PNL CSV file to begin analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
