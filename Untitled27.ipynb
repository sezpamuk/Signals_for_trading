import numpy as np
import pandas as pd
import random
from collections import deque
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
import pandas_ta as ta 

# For the stress barometer
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, roc_auc_score

# Ensure reproducibility for consistent results
np.random.seed(42)
tf.random.set_seed(42)

# --- 0. Stress Barometer Module ---
class MarketStressBarometer:
    def __init__(self, data, target_index_col, future_lookback_days=5, spread_increase_threshold=0.02):
        """
        Initializes the Market Stress Barometer.

        Args:
            data (pd.DataFrame): Historical data for all CDS indexes.
            target_index_col (str): The primary CDS index to define stress events.
            future_lookback_days (int): Number of days into the future to check for spread increase.
            spread_increase_threshold (float): Percentage increase in spread to classify as a stress event.
        """
        self.data = data.copy()
        self.target_index_col = target_index_col
        self.future_lookback_days = future_lookback_days
        self.spread_increase_threshold = spread_increase_threshold
        self.model = None
        self.feature_columns = [] # To store names of features used by the barometer

        self._prepare_barometer_data()

    def _prepare_barometer_data(self):
        """
        Prepares features and target variable for the stress barometer.
        Target: Binary (1 if target spread increases significantly in future, 0 otherwise).
        Features: Current and lagged values, returns, and indicators for ALL CDS indexes.
        """
        print("Preparing data for Market Stress Barometer...")
        
        # Define all CDS index columns from the input data (excluding 'Date' if it's a column)
        cds_index_cols = [col for col in self.data.columns if col not in ['DATE', 'TRADABLE_PRICE', 'RSI', 'MACD', 'MACD_SIGNAL', 'MACD_HIST', 'RETURN_1D', 'RETURN_1W', 'RETURN_2W', 'RETURN_1M']]
        
        # Create features for each CDS index
        for col in cds_index_cols:
            # Lagged values
            self.data[f'{col}_Lag1'] = self.data[col].shift(1)
            self.data[f'{col}_Lag5'] = self.data[col].shift(5) # 1 week lag
            
            # Daily returns (percentage change in spread) - Barometer still uses pct_change as it's common for volatility etc.
            self.data[f'{col}_DailyReturn'] = self.data[col].pct_change(1)
            
            # Volatility (rolling standard deviation of daily returns)
            self.data[f'{col}_Vol_5D'] = self.data[f'{col}_DailyReturn'].rolling(window=5).std()
            
            # RSI on the spread itself
            self.data.ta.rsi(close=self.data[col], length=14, append=True, col_names=(f'RSI_{col}',))
            
            # MACD on the spread itself
            macd_data = self.data.ta.macd(close=self.data[col], fast=12, slow=26, signal=9, append=True, col_names=(f'MACD_{col}', f'MACDs_{col}', f'MACDh_{col}'))
            if isinstance(macd_data, pd.DataFrame): 
                self.data[f'MACD_{col}'] = macd_data[f'MACD_{col}']
                self.data[f'MACDs_{col}'] = macd_data[f'MACDs_{col}']
                self.data[f'MACDh_{col}'] = macd_data[f'MACDh_{col}']
            else: 
                self.data[f'MACD_{col}'] = macd_data


        # Define the target variable: Future significant spread increase
        future_spread = self.data[self.target_index_col].shift(-self.future_lookback_days)
        spread_change = (future_spread - self.data[self.target_index_col]) / self.data[self.target_index_col]
        self.data['Is_Stressed_Future'] = (spread_change >= self.spread_increase_threshold).astype(int)

        self.data.dropna(inplace=True)

        self.feature_columns = [col for col in self.data.columns if col.endswith(('_Lag1', '_Lag5', '_DailyReturn', '_Vol_5D', '_RSI', '_MACD', '_MACDs', '_MACDh'))]
        self.feature_columns.extend(cds_index_cols)
        self.feature_columns = sorted(list(set(self.feature_columns)))

        # Normalize features
        for col in self.feature_columns:
            min_val = self.data[col].min()
            max_val = self.data[col].max()
            if max_val - min_val != 0:
                self.data[col] = (self.data[col] - min_val) / (max_val - min_val)
            else:
                self.data[col] = 0.0 

        print(f"Barometer features created: {len(self.feature_columns)}")
        print(f"Stress events detected: {self.data['Is_Stressed_Future'].sum()} out of {len(self.data)} data points.")

    def train_barometer(self):
        """Trains the Random Forest Classifier barometer model."""
        if self.data.empty or not self.feature_columns:
            print("Error: Barometer data or features are not ready for training.")
            return

        X = self.data[self.feature_columns]
        y = self.data['Is_Stressed_Future']

        if y.nunique() < 2:
            print("Warning: Target variable 'Is_Stressed_Future' has only one unique value. Cannot train classifier.")
            print("This might happen if your data is too short or the threshold is too high/low.")
            self.model = None 
            return

        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
        
        print(f"Training barometer on {len(X_train)} samples, testing on {len(X_test)} samples.")

        self.model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')
        self.model.fit(X_train, y_train)

        y_pred = self.model.predict(X_test)
        y_prob = self.model.predict_proba(X_test)[:, 1] 

        print("\nMarket Stress Barometer Performance:")
        print(classification_report(y_test, y_pred))
        print(f"ROC AUC Score: {roc_auc_score(y_test, y_prob):.4f}")

    def get_stress_probability(self, current_features):
        """
        Predicts the stress probability for a given set of current features.
        
        Args:
            current_features (pd.Series or np.array): Current feature values for the barometer.
                                                      Must match the order of self.feature_columns.
        Returns:
            float: Probability of a future stress event (between 0 and 1).
        """
        if self.model is None:
            return 0.5 
        
        if isinstance(current_features, pd.Series):
            input_df = pd.DataFrame([current_features[self.feature_columns].values], columns=self.feature_columns)
        elif isinstance(current_features, np.ndarray):
            if current_features.shape[0] != len(self.feature_columns):
                 raise ValueError(f"Input feature array size mismatch. Expected {len(self.feature_columns)}, got {current_features.shape[0]}.")
            input_df = pd.DataFrame([current_features], columns=self.feature_columns)
        else:
            raise TypeError("current_features must be a pandas Series or numpy array.")

        stress_prob = self.model.predict_proba(input_df)[0, 1]
        return stress_prob


# --- 1. Define the Trading Environment (Updated for Barometer and Spread Differences) ---
class CDSTradingEnv:
    def __init__(self, data, target_index_col, barometer_model, initial_capital=100000, commission_rate=0.0001, spread_cost=0.0005):
        """
        Initializes the CDS Trading Environment, now including a market stress barometer.

        Args:
            data (pd.DataFrame): Historical data for CDS indexes.
            target_index_col (str): The name of the column for the CDS index to be traded.
            barometer_model (MarketStressBarometer): An instance of the trained stress barometer.
            initial_capital (float): Starting capital.
            commission_rate (float): Commission per trade.
            spread_cost (float): Bid-ask spread/slippage.
        """
        if target_index_col not in data.columns:
            raise ValueError(f"'{target_index_col}' not found in data columns. Available: {data.columns.tolist()}")

        self.data = data.copy() 
        self.target_index_col = target_index_col
        self.barometer_model = barometer_model 
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.commission_rate = commission_rate
        self.spread_cost = spread_cost
        self.shares = 0 
        
        self.max_spread = self.data[self.target_index_col].max()
        self.data['Tradable_Price'] = self.max_spread - self.data[self.target_index_col] + 1.0 
        
        self.price_history = self.data['Tradable_Price'].values
        self.spread_history = self.data[self.target_index_col].values 

        self.current_step = 0
        self.history = [] 
        self.position = 0 

        self.window_size = 20 
        self.action_space = [0, 1, 2] 

        self._prepare_features() 

        self.reset()

    def _prepare_features(self):
        spread_series = self.data[self.target_index_col]
        
        # --- MODIFICATION START ---
        # Return Horizons (now as spread differences in basis points)
        self.data['Spread_Diff_1D'] = spread_series.diff(1)
        self.data['Spread_Diff_1W'] = spread_series.diff(5) 
        self.data['Spread_Diff_2W'] = spread_series.diff(10) 
        self.data['Spread_Diff_1M'] = spread_series.diff(20) 
        # --- MODIFICATION END ---

        # Technical Indicators using pandas_ta on Tradable_Price
        tradable_price_series = self.data['Tradable_Price']
        self.data.ta.rsi(close=tradable_price_series, length=14, append=True)
        self.data.ta.macd(close=tradable_price_series, fast=12, slow=26, signal=9, append=True)

        self.data['RSI'] = self.data[f'RSI_14']
        self.data['MACD'] = self.data[f'MACD_12_26_9']
        self.data['MACD_Signal'] = self.data[f'MACDs_12_26_9']
        self.data['MACD_Hist'] = self.data[f'MACDh_12_26_9']

        # --- Generate Stress Barometer Signal ---
        cds_index_cols = [col for col in self.data.columns if col in ['CDX_IG', 'CDX_EM', 'ITRX_MAIN', 'ITRX_XOVER']]
        for col in cds_index_cols:
            self.data[f'{col}_Lag1'] = self.data[col].shift(1)
            self.data[f'{col}_Lag5'] = self.data[col].shift(5) 
            self.data[f'{col}_DailyReturn'] = self.data[col].pct_change(1) # Barometer features still use pct_change for consistency
            self.data[f'{col}_Vol_5D'] = self.data[f'{col}_DailyReturn'].rolling(window=5).std()
            self.data.ta.rsi(close=self.data[col], length=14, append=True, col_names=(f'RSI_{col}',))
            macd_data = self.data.ta.macd(close=self.data[col], fast=12, slow=26, signal=9, append=True, col_names=(f'MACD_{col}', f'MACDs_{col}', f'MACDh_{col}'))
            if isinstance(macd_data, pd.DataFrame):
                self.data[f'MACD_{col}'] = macd_data[f'MACD_{col}']
                self.data[f'MACDs_{col}'] = macd_data[f'MACDs_{col}']
                self.data[f'MACDh_{col}'] = macd_data[f'MACDh_{col}']
            else:
                self.data[f'MACD_{col}'] = macd_data


        barometer_feature_cols = self.barometer_model.feature_columns
        barometer_X = self.data[barometer_feature_cols].copy()
        barometer_X.fillna(method='bfill', inplace=True)
        barometer_X.fillna(0, inplace=True)

        if self.barometer_model.model: 
            self.data['Stress_Probability'] = self.barometer_model.model.predict_proba(barometer_X)[:, 1]
        else:
            self.data['Stress_Probability'] = 0.5 

        self.data.fillna(method='bfill', inplace=True) 
        self.data.fillna(0, inplace=True) 

        # Features to be included in the RL agent's state vector
        self.feature_cols = [
            'Tradable_Price', 
            # --- MODIFICATION START ---
            'Spread_Diff_1D', 'Spread_Diff_1W', 'Spread_Diff_2W', 'Spread_Diff_1M', # Updated names
            # --- MODIFICATION END ---
            'RSI', 'MACD', 'MACD_Signal', 'MACD_Hist',
            'Stress_Probability' 
        ]
        
        # Scale features for RL agent's neural network
        self.scalers = {}
        for col in self.feature_cols:
            min_val = self.data[col].min()
            max_val = self.data[col].max()
            if max_val - min_val != 0:
                self.data[col + '_Scaled'] = (self.data[col] - min_val) / (max_val - min_val)
                self.scalers[col] = {'min': min_val, 'max': max_val}
            else:
                self.data[col + '_Scaled'] = 0.0 
                self.scalers[col] = {'min': min_val, 'max': max_val} 
        
        self.scaled_feature_cols = [col + '_Scaled' for col in self.feature_cols]
        
        self.start_step_offset = max(self.window_size, 26, self.barometer_model.future_lookback_days + 5) 
        
        if len(self.data) <= self.start_step_offset:
            raise ValueError(f"Not enough data points ({len(self.data)}) for the required start offset ({self.start_step_offset}). Please provide more historical data.")

        self.price_history = self.data['Tradable_Price'].values 
        
        print(f"RL Agent features prepared. State size will be based on {len(self.scaled_feature_cols) * self.window_size + 1} elements.")

    def _get_state(self):
        if self.current_step < self.start_step_offset:
            return np.zeros(len(self.scaled_feature_cols) * self.window_size + 1)
        
        state_window_data = self.data.loc[self.data.index[self.current_step - self.window_size : self.current_step], self.scaled_feature_cols].values
        
        state = state_window_data.flatten()
        state = np.append(state, self.position)
        return state

    def step(self, action):
        current_tradable_price = self.price_history[self.current_step]
        current_spread = self.spread_history[self.current_step] 
        reward = 0
        done = False

        self.current_step += 1
        if self.current_step >= len(self.price_history):
            done = True

        if action == 1:  # Buy
            if self.position == 0: 
                buy_amount = self.capital / (current_tradable_price * (1 + self.commission_rate + self.spread_cost))
                if buy_amount * current_tradable_price > 0: 
                    self.shares += buy_amount
                    self.capital -= buy_amount * current_tradable_price * (1 + self.commission_rate + self.spread_cost)
                    self.position = 1
                    self.entry_tradable_price = current_tradable_price 
                    self.entry_shares = buy_amount

        elif action == 2:  # Sell
            if self.position == 1 and self.shares > 0: 
                sale_value = self.shares * current_tradable_price * (1 - self.commission_rate - self.spread_cost)
                
                trade_pnl = (current_tradable_price - self.entry_tradable_price) * self.entry_shares
                reward = trade_pnl / self.initial_capital * 10.0 
                
                if trade_pnl < 0:
                    reward -= 0.5 
                    
                self.capital += sale_value
                self.shares = 0
                self.position = 0
                self.entry_tradable_price = None 

        next_state = self._get_state()

        if done:
            final_value = self.capital + self.shares * current_tradable_price * (1 - self.commission_rate)
            reward += (final_value - self.initial_capital) / self.initial_capital * 100.0 
            
            if self.shares != 0:
                current_hold_value = self.shares * current_tradable_price 
                if self.position == 1: 
                    initial_allocation = self.initial_capital - self.capital 
                    if initial_allocation > 0:
                         pnl_on_hold = (current_hold_value - initial_allocation) / initial_allocation
                         if pnl_on_hold < 0:
                            reward += pnl_on_hold * 5.0 
            
            if final_value < self.initial_capital:
                reward -= (self.initial_capital - final_value) / self.initial_capital * 20.0 
            
        self.history.append({
            'date': self.data.index[self.current_step-1], 
            'capital': self.capital,
            'shares': self.shares,
            'position': self.position,
            'spread': current_spread, 
            'tradable_price': current_tradable_price, 
            'action': action,
            'reward': reward,
            'portfolio_value': self.get_portfolio_value(),
            'stress_probability': self.data['Stress_Probability'].iloc[self.current_step-1] 
        })

        return next_state, reward, done, {}

    def get_portfolio_value(self):
        current_tradable_price = self.price_history[self.current_step-1] if self.current_step > 0 else self.price_history[0]
        return self.capital + self.shares * current_tradable_price


# --- 2. Implement the Q-Learning Agent (No changes needed here) ---
class DQNAgent:
    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.95,
                 epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01,
                 batch_size=64, memory_size=2000):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=memory_size)
        self.learning_rate = learning_rate
        self.gamma = gamma    
        self.epsilon = epsilon  
        self.epsilon_decay = epsilon_decay
        self.epsilon_min = epsilon_min
        self.batch_size = batch_size
        self.model = self._build_model()

    def _build_model(self):
        model = Sequential()
        model.add(Dense(128, input_dim=self.state_size, activation='relu')) 
        model.add(Dense(64, activation='relu'))
        model.add(Dense(self.action_size, activation='linear'))
        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
        return model

    def remember(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))

    def act(self, state):
        if np.random.rand() <= self.epsilon:
            return random.randrange(self.action_size) 
        
        state_reshaped = state.reshape(1, -1) 
        act_values = self.model.predict(state_reshaped, verbose=0)
        return np.argmax(act_values[0]) 

    def replay(self):
        if len(self.memory) < self.batch_size:
            return

        minibatch = random.sample(self.memory, self.batch_size)
        states, targets = [], []
        
        for state, action, reward, next_state, done in minibatch:
            state_reshaped = state.reshape(1, -1)
            next_state_reshaped = next_state.reshape(1, -1)
            
            target = reward
            if not done:
                target = reward + self.gamma * np.amax(self.model.predict(next_state_reshaped, verbose=0)[0])
            
            current_q_values = self.model.predict(state_reshaped, verbose=0)[0]
            current_q_values[action] = target
            
            states.append(state)
            targets.append(current_q_values)
            
        self.model.fit(np.array(states), np.array(targets), epochs=1, verbose=0)
        
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# --- 3. Training Loop (No changes needed here) ---
def train_agent(env, agent, episodes=100):
    portfolio_values = []
    
    for e in range(episodes):
        state = env.reset()
        done = False
        total_reward = 0
        
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay
        if e == 0: 
            agent.epsilon = 1.0

        while not done:
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            
            state_np = np.array(state)
            next_state_np = np.array(next_state)

            agent.remember(state_np, action, reward, next_state_np, done)
            state = next_state
            total_reward += reward
            
            agent.replay()
        
        final_portfolio_value = env.get_portfolio_value()
        portfolio_values.append(final_portfolio_value)
        
        print(f"Episode {e+1}/{episodes}, Final Portfolio Value: ${final_portfolio_value:,.2f}, Total Reward: {total_reward:.2f}, Epsilon: {agent.epsilon:.2f}")

    return portfolio_values

# --- 4. Load your CDS Data ---
csv_file_path = 'cds_data.csv' 

try:
    df_cds_raw = pd.read_csv(csv_file_path, index_col='Date', parse_dates=True)
    df_cds_raw.columns = df_cds_raw.columns.str.upper() 
    print(f"Successfully loaded data from {csv_file_path}. Columns: {df_cds_raw.columns.tolist()}")

    TARGET_CDS_INDEX = 'CDX_IG' # <--- CHANGE THIS to the index you want to trade!

    if TARGET_CDS_INDEX not in df_cds_raw.columns:
        raise KeyError(f"The specified TARGET_CDS_INDEX '{TARGET_CDS_INDEX}' is not in the CSV file.")
    
except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found.")
    print("Please ensure your CSV file is in the same directory as this script, or provide the full path.")
    print("Example CSV format:")
    print("Date,CDX_IG,CDX_EM,ITRX_Main,ITRX_XOVER")
    print("2020-01-01,100.00,200.00,50.00,300.00")
    print("... (add more data)")
    exit() 
except KeyError as e:
    print(f"Error: Missing expected column in CSV: {e}. Please check your column names.")
    print(f"Expected columns: Date, CDX_IG, CDX_EM, ITRX_Main, ITRX_XOVER (case-insensitive for access).")
    exit()

# --- 5. Initialize and Train the Market Stress Barometer ---
# Parameters for barometer:
FUTURE_LOOKBACK_DAYS = 5 
SPREAD_INCREASE_THRESHOLD = 0.02 

barometer = MarketStressBarometer(df_cds_raw.copy(), TARGET_CDS_INDEX, 
                                  future_lookback_days=FUTURE_LOOKBACK_DAYS, 
                                  spread_increase_threshold=SPREAD_INCREASE_THRESHOLD)
barometer.train_barometer()

# --- 6. Initialize RL Environment and Agent ---
env = CDSTradingEnv(df_cds_raw.copy(), target_index_col=TARGET_CDS_INDEX, barometer_model=barometer) 
state_size = env._get_state().shape[0]
action_size = len(env.action_space)

agent = DQNAgent(state_size, action_size)

print(f"\nTraining RL agent for {TARGET_CDS_INDEX} with Stress Barometer on {len(env.data)} data points...")
training_results = train_agent(env, agent, episodes=200) 

# --- 7. Visualization Functions ---

def plot_training_results(training_results, initial_capital, index_name):
    plt.figure(figsize=(14, 7))
    plt.plot(training_results)
    plt.title(f'Final Portfolio Value per Episode during Training ({index_name})', fontsize=16)
    plt.xlabel('Episode', fontsize=12)
    plt.ylabel('Final Portfolio Value', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')
    plt.legend()
    plt.tight_layout()
    plt.show()

def plot_backtest_results(env_history, price_data, window_size, initial_capital, index_name):
    fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(18, 16), sharex=True, gridspec_kw={'height_ratios': [3, 1, 1]})

    # --- Plot 1: Spread Chart with Buy/Sell Signals ---
    dates_for_plot = [pd.to_datetime(h['date']) for h in env_history]
    spreads_for_plot = [h['spread'] for h in env_history]

    ax1.plot(dates_for_plot, spreads_for_plot, label=f'{index_name} Spread (bps)', color='skyblue', linewidth=1.5)
    
    ax1.invert_yaxis() 
    
    buy_signals_x, buy_signals_y = [], []
    sell_signals_x, sell_signals_y = [], []
    
    for i, record in enumerate(env_history):
        date_index = record['date'] 
        spread = record['spread']
        action = record['action']
        
        if action == 1 and (i == 0 or env_history[i-1]['position'] == 0) and record['position'] == 1:
             buy_signals_x.append(date_index)
             buy_signals_y.append(spread)
        elif action == 2 and (i > 0 and env_history[i-1]['position'] == 1) and record['position'] == 0:
             sell_signals_x.append(date_index)
             sell_signals_y.append(spread)

    ax1.scatter(buy_signals_x, buy_signals_y, marker='^', color='green', label='Buy Signal (Spreads Tighten)', alpha=0.9, s=150, zorder=5)
    ax1.scatter(sell_signals_x, sell_signals_y, marker='v', color='red', label='Sell Signal (Spreads Widen)', alpha=0.9, s=150, zorder=5)
    
    ax1.set_title(f'{index_name} Spread with Trading Signals (Inverted Y-axis)', fontsize=16)
    ax1.set_ylabel('CDS Spread (bps)', fontsize=12)
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.legend()
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    ax1.xaxis.set_major_locator(mdates.AutoLocator())
    fig.autofmt_xdate()

    # --- Plot 2: Portfolio Value ---
    portfolio_values = [h['portfolio_value'] for h in env_history]
    
    ax2.plot(dates_for_plot, portfolio_values, label='Portfolio Value', color='blue', linewidth=2)
    ax2.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')
    ax2.set_title('Portfolio Value Over Time', fontsize=16)
    ax2.set_xlabel('Date', fontsize=12)
    ax2.set_ylabel('Portfolio Value', fontsize=12)
    ax2.grid(True, linestyle='--', alpha=0.7)
    ax2.legend()

    # --- Plot 3: Market Stress Barometer ---
    stress_probabilities = [h['stress_probability'] for h in env_history]
    ax3.plot(dates_for_plot, stress_probabilities, label='Stress Probability', color='purple', linewidth=1.5)
    ax3.axhline(y=0.5, color='gray', linestyle='--', alpha=0.7, label='Neutral Stress Level')
    ax3.set_title('Market Stress Barometer Signal', fontsize=16)
    ax3.set_xlabel('Date', fontsize=12)
    ax3.set_ylabel('Probability of Stress (0-1)', fontsize=12)
    ax3.grid(True, linestyle='--', alpha=0.7)
    ax3.legend()
    ax3.set_ylim(0, 1) 

    plt.tight_layout()
    plt.show()

# --- 8. Backtesting Module (Updated for Barometer) ---
def backtest_agent(env_class, agent, data_to_backtest, target_index_col, barometer_model):
    """
    Runs the trained agent on a given dataset and records performance.
    
    Args:
        env_class (class): The CDSTradingEnv class itself.
        agent (DQNAgent): The trained RL agent.
        data_to_backtest (pd.DataFrame): The historical data for backtesting.
        target_index_col (str): The name of the column representing the index being traded.
        barometer_model (MarketStressBarometer): The trained stress barometer model.
    
    Returns:
        float: Final portfolio value.
        list: History of the environment (for plotting).
    """
    backtest_env = env_class(data_to_backtest, target_index_col=target_index_col, 
                             barometer_model=barometer_model, 
                             initial_capital=env.initial_capital,
                             commission_rate=env.commission_rate,
                             spread_cost=env.spread_cost)
    
    state = backtest_env.reset()
    done = False
    
    agent.epsilon = 0.00 
    
    while not done:
        action = agent.act(state)
        next_state, reward, done, _ = backtest_env.step(action)
        state = next_state

    final_value = backtest_env.get_portfolio_value()
    print(f"\nBacktesting Complete. Final Portfolio Value: ${final_value:,.2f}")
    return final_value, backtest_env.history

# --- Execute Training, Backtesting and Visualization ---

plot_training_results(training_results, env.initial_capital, TARGET_CDS_INDEX)

print(f"\n--- Starting Backtesting for {TARGET_CDS_INDEX} with Barometer ---")
final_backtest_value, backtest_history = backtest_agent(CDSTradingEnv, agent, df_cds_raw.copy(), TARGET_CDS_INDEX, barometer)

plot_backtest_results(backtest_history, df_cds_raw, env.start_step_offset, env.initial_capital, TARGET_CDS_INDEX)
