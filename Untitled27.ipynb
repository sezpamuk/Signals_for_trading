# Function to find best hedge for each bond
def find_best_hedge(bond_ts, cds_ts, bond_id):
    bond_spreads = bond_ts[bond_id]
    correlations = {}
    hedge_ratios = {}
    r_squared = {}
    
    for cds_idx in cds_ts.columns:
        # Calculate correlation
        corr = np.corrcoef(bond_spreads, cds_ts[cds_idx])[0,1]
        correlations[cds_idx] = corr
        
        # Calculate hedge ratio via regression
        X = cds_ts[cds_idx].values.reshape(-1,1)
        y = bond_spreads.values
        model = LinearRegression().fit(X, y)
        hedge_ratios[cds_idx] = model.coef_[0]
        r_squared[cds_idx] = model.score(X, y)
    
    best_hedge = max(correlations, key=correlations.get)
    return {
        'bond_id': bond_id,
        'best_hedge': best_hedge,
        'correlation': correlations[best_hedge],
        'hedge_ratio': hedge_ratios[best_hedge],
        'r_squared': r_squared[best_hedge],
        'all_correlations': correlations,
        'all_rsquared': r_squared
    }

# Analyze first 10 bonds for demonstration
hedge_analysis = [find_best_hedge(bond_ts, cds_ts, bond_id) for bond_id in bond_ts.columns[:10]]

# Display results
for analysis in hedge_analysis[:3]:  # Show first 3 for brevity
    print(f"Bond: {analysis['bond_id']}")
    print(f"Best Hedge: {analysis['best_hedge']} (Correlation: {analysis['correlation']:.2f}, R²: {analysis['r_squared']:.2f})")
    print(f"Hedge Ratio: {analysis['hedge_ratio']:.4f}")
    print("---")


import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression

def get_all_hedge_relationships(bond_ts, cds_ts, bond_id):
    """
    Calculate hedge relationships between a bond and all CDS indexes
    Returns a list of dictionaries with metrics for each CDS index
    """
    bond_spreads = bond_ts[bond_id]
    records = []
    
    for cds_idx in cds_ts.columns:
        # Calculate correlation
        corr = np.corrcoef(bond_spreads, cds_ts[cds_idx])[0, 1]
        
        # Calculate hedge ratio via regression
        X = cds_ts[cds_idx].values.reshape(-1, 1)
        y = bond_spreads.values
        model = LinearRegression().fit(X, y)
        hedge_ratio = model.coef_[0]
        r_squared = model.score(X, y)
        intercept = model.intercept_
        
        # Calculate hedge effectiveness metrics
        residual = y - model.predict(X)
        residual_std = np.std(residual)
        hedge_effectiveness = 1 - (residual_std / np.std(y))
        
        records.append({
            'bond_id': bond_id,
            'cds_index': cds_idx,
            'correlation': corr,
            'hedge_ratio': hedge_ratio,
            'r_squared': r_squared,
            'intercept': intercept,
            'residual_std': residual_std,
            'hedge_effectiveness': hedge_effectiveness,
            'is_hedgeable': r_squared > 0.5  # Custom threshold
        })
    
    return records

# Generate comprehensive results DataFrame
all_results = []

# Process all bonds - use bond_ts.columns for all bonds
for bond_id in bond_ts.columns:
    results = get_all_hedge_relationships(bond_ts, cds_ts, bond_id)
    all_results.extend(results)

# Create DataFrame with all relationships
relationships_df = pd.DataFrame(all_results)

# Create best hedge summary DataFrame
best_hedge_df = relationships_df.sort_values('r_squared', ascending=False)\
                                .groupby('bond_id').first().reset_index()

# Add best hedge details to bond data
bond_data_full = bond_data.merge(
    best_hedge_df[['bond_id', 'cds_index', 'hedge_ratio', 'r_squared', 'is_hedgeable']],
    on='bond_id',
    how='left'
)

# Rename columns for clarity
bond_data_full = bond_data_full.rename(columns={
    'cds_index': 'best_hedge',
    'hedge_ratio': 'best_hedge_ratio',
    'r_squared': 'best_hedge_r2'
})

# Save results to CSV
relationships_df.to_csv('all_hedge_relationships.csv', index=False)
bond_data_full.to_csv('bond_data_with_best_hedge.csv', index=False)

print("All relationships DataFrame:")
print(relationships_df.head())
print("\nBest hedge summary:")
print(best_hedge_df.head())
print("\nBond data with best hedge:")
print(bond_data_full.head())

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from scipy.optimize import minimize

# Generate synthetic bond spread changes (1000 bonds, 500 days)
np.random.seed(42)
n_bonds = 1000
n_days = 500
bond_returns = pd.DataFrame(
    np.random.normal(0, 0.1, (n_days, n_bonds)),
    columns=[f'BOND_{i}' for i in range(n_bonds)]
)

# Add sector/region factors to create correlation structure
sectors = ['Financial', 'Industrial', 'Tech', 'Energy', 'Utility']
regions = ['NA', 'EU', 'APAC', 'EM']
for i, bond in enumerate(bond_returns.columns):
    sector_factor = np.random.choice(sectors)
    region_factor = np.random.choice(regions)
    sector_ret = np.random.normal(0, 0.05, n_days)
    region_ret = np.random.normal(0, 0.03, n_days)
    bond_returns[bond] += sector_ret + region_ret

# Generate synthetic CDS index returns (4 indexes)
cds_returns = pd.DataFrame({
    'CDX_IG': np.random.normal(0, 0.08, n_days),
    'CDX_HY': np.random.normal(0, 0.12, n_days),
    'ITRAXX_MAIN': np.random.normal(0, 0.07, n_days),
    'ITRAXX_XOVER': np.random.normal(0, 0.15, n_days)
})

# Add common market factor to all instruments
market_factor = np.random.normal(0, 0.05, n_days)
bond_returns = bond_returns + market_factor[:, np.newaxis]
cds_returns = cds_returns + market_factor[:, np.newaxis]

# Portfolio Cs01 values (dollar sensitivity per bp)
cs01_values = pd.Series(
    np.random.lognormal(5, 0.3, n_bonds),
    index=bond_returns.columns
)

### Step 1: Perform PCA on bond spread changes
pca = PCA(n_components=5)
pca.fit(bond_returns)

print(f"Explained variance: {pca.explained_variance_ratio_}")
print(f"Cumulative explained variance: {np.cumsum(pca.explained_variance_ratio_)}")

# Transform bond returns to factor space
bond_factor_exposures = pca.transform(bond_returns)  # Days × factors

### Step 2: Calculate portfolio factor exposures
# Weighted average of factor exposures based on Cs01
portfolio_factor_exposure = np.zeros(5)
for i, bond in enumerate(bond_returns.columns):
    # The factor exposure per $1 of Cs01
    exposure_per_dollar = pca.components_[:, i] / cs01_values[bond]
    portfolio_factor_exposure += exposure_per_dollar * cs01_values[bond]

# Normalize by total portfolio Cs01
total_cs01 = cs01_values.sum()
portfolio_factor_exposure /= total_cs01

print("\nPortfolio factor exposures:")
print(portfolio_factor_exposure)

### Step 3: Map CDS indexes to PCA factors
cds_factor_exposures = np.zeros((4, 5))  # Indexes × factors

for i, idx in enumerate(cds_returns.columns):
    # Regress CDS returns on PCA factors
    cds_ret = cds_returns[idx].values
    factor_exposure = np.linalg.lstsq(bond_factor_exposures, cds_ret, rcond=None)[0]
    cds_factor_exposures[i] = factor_exposure

print("\nCDS index factor exposures:")
print(pd.DataFrame(cds_factor_exposures, index=cds_returns.columns))

### Step 4: Optimize hedge ratios
def hedge_objective(hedge_weights, portfolio_exposure, cds_exposures):
    """Minimize residual factor exposure after hedging"""
    hedged_exposure = portfolio_exposure - np.dot(hedge_weights, cds_exposures)
    return np.sum(hedged_exposure**2)  # Sum of squared residuals

def hedge_constraint(hedge_weights):
    """Maximum total hedge capacity constraint"""
    return 1000000 - np.sum(np.abs(hedge_weights))  # $1MM cap

# Initial guess (equal weighting)
x0 = np.zeros(len(cds_returns.columns))

# Bounds: allow both long and short positions
bounds = [(-100000, 100000) for _ in range(len(cds_returns.columns))]

# Constraints
constraints = [{'type': 'ineq', 'fun': hedge_constraint}]

# Solve optimization
result = minimize(
    hedge_objective,
    x0,
    args=(portfolio_factor_exposure, cds_factor_exposures),
    bounds=bounds,
    constraints=constraints,
    method='SLSQP'
)

optimal_hedge_weights = result.x
print("\nOptimal hedge notionals:")
for idx, weight in zip(cds_returns.columns, optimal_hedge_weights):
    print(f"{idx}: ${weight:,.2f}")

### Step 5: Risk monitoring with hedge triggers
def calculate_residual_risk(bond_rets, cds_rets, hedge_weights, cs01_values):
    """Calculate daily residual risk after hedging"""
    # Portfolio dollar returns
    portfolio_dollar_returns = bond_rets.dot(cs01_values)
    
    # Hedge portfolio dollar returns
    hedge_dollar_returns = cds_rets.dot(hedge_weights)
    
    # Residual risk
    residual = portfolio_dollar_returns - hedge_dollar_returns
    return residual

# Calculate historical residual risk
residual_risk = calculate_residual_risk(
    bond_returns,
    cds_returns,
    optimal_hedge_weights,
    cs01_values
)

# Set risk thresholds (using historical standard deviation)
risk_std = residual_risk.std()
upper_threshold = 2 * risk_std
lower_threshold = -2 * risk_std
rebalance_threshold = 3 * risk_std

def monitor_risk(current_residual, upper_thresh, lower_thresh, rebalance_thresh):
    """Determine hedge adjustment based on current risk"""
    if current_residual > upper_thresh:
        return "SELL hedge"
    elif current_residual < lower_thresh:
        return "BUY hedge"
    elif abs(current_residual) > rebalance_thresh:
        return "REBALANCE entire hedge"
    else:
        return "NO ACTION"

# Example monitoring
current_residual = residual_risk.iloc[-1]  # Most recent residual
action = monitor_risk(current_residual, upper_threshold, lower_threshold, rebalance_threshold)
print(f"\nCurrent residual risk: ${current_residual:,.2f}")
print(f"Recommended action: {action}")

### Step 6: Factor Exposure Dashboard (Optional)
def create_exposure_dashboard(portfolio_exposure, cds_exposures, hedge_weights):
    """Create factor exposure visualization"""
    import matplotlib.pyplot as plt
    
    # Before and after hedge exposures
    hedged_exposure = portfolio_exposure - np.dot(hedge_weights, cds_exposures)
    
    # Plot
    fig, ax = plt.subplots(figsize=(10, 6))
    width = 0.35
    x = np.arange(5)
    
    ax.bar(x - width/2, portfolio_exposure, width, label='Before Hedge')
    ax.bar(x + width/2, hedged_exposure, width, label='After Hedge')
    
    ax.set_ylabel('Factor Exposure')
    ax.set_title('Portfolio Factor Exposure')
    ax.set_xticks(x)
    ax.set_xticklabels([f'Factor {i+1}' for i in range(5)])
    ax.legend()
    ax.axhline(0, color='black', linewidth=0.8)
    
    plt.show()
    return fig

# Generate exposure dashboard
create_exposure_dashboard(portfolio_factor_exposure, cds_factor_exposures, optimal_hedge_weights)

import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from scipy.optimize import minimize
import matplotlib.pyplot as plt

# Generate synthetic bond spread data (1000 bonds, 500 days)
np.random.seed(42)
n_bonds = 1000
n_days = 500

# Create 5 true underlying factors (systematic risk drivers)
true_factors = np.random.normal(0, 0.1, (n_days, 5))

# Generate bond loadings on these factors
bond_loadings = np.random.normal(0, 1, (n_bonds, 5))

# Generate bond-specific returns (idiosyncratic risk)
idiosyncratic_returns = np.random.normal(0, 0.05, (n_days, n_bonds))

# Calculate bond spread changes
bond_returns = np.dot(true_factors, bond_loadings.T) + idiosyncratic_returns
bond_returns = pd.DataFrame(bond_returns, columns=[f'BOND_{i}' for i in range(n_bonds)])

# Generate synthetic CDS index returns (4 indexes)
cds_returns = pd.DataFrame({
    'CDX_IG': np.random.normal(0, 0.08, n_days),
    'CDX_HY': np.random.normal(0, 0.12, n_days),
    'ITRAXX_MAIN': np.random.normal(0, 0.07, n_days),
    'ITRAXX_XOVER': np.random.normal(0, 0.15, n_days)
})

# Add common market factor to CDS indexes
cds_returns += np.random.normal(0, 0.05, n_days)[:, np.newaxis]

# Portfolio Cs01 values (dollar sensitivity per bp)
cs01_values = pd.Series(
    np.random.lognormal(5, 0.3, n_bonds),
    index=bond_returns.columns
)

### Step 1: Perform PCA on bond spread changes
pca = PCA(n_components=5)
pca.fit(bond_returns)

print("PCA Explained Variance Ratio:")
print(pca.explained_variance_ratio_)
print("\nCumulative Explained Variance:")
print(np.cumsum(pca.explained_variance_ratio_))

# Transform bond returns to factor space
bond_factor_scores = pca.transform(bond_returns)  # Days × factors

### Step 2: Calculate portfolio factor exposures
# Get PCA loadings (components_ are already normalized)
pca_loadings = pca.components_.T  # Bonds × factors

# Calculate portfolio exposure to each factor
portfolio_factor_exposure = np.zeros(5)
for i, bond in enumerate(bond_returns.columns):
    # Contribution = loading * Cs01
    portfolio_factor_exposure += pca_loadings[i] * cs01_values[bond]

# Normalize by total portfolio Cs01
total_cs01 = cs01_values.sum()
portfolio_factor_exposure /= total_cs01

print("\nPortfolio Factor Exposures:")
print(portfolio_factor_exposure)

### Step 3: Map CDS indexes to PCA factors
cds_factor_exposures = np.zeros((len(cds_returns.columns), 5))  # Indexes × factors

for i, idx in enumerate(cds_returns.columns):
    # Regress CDS returns on PCA factor scores
    X = bond_factor_scores  # PCA factor scores (n_days × n_factors)
    y = cds_returns[idx].values
    
    # Solve y = Xβ
    beta = np.linalg.lstsq(X, y, rcond=None)[0]
    cds_factor_exposures[i] = beta

print("\nCDS Index Factor Exposures:")
print(pd.DataFrame(cds_factor_exposures, index=cds_returns.columns, 
                  columns=[f'Factor {i+1}' for i in range(5)]))

### Step 4: Optimize hedge ratios
def hedge_objective(hedge_weights):
    """Minimize residual factor exposure after hedging"""
    hedged_exposure = portfolio_factor_exposure - np.dot(hedge_weights, cds_factor_exposures)
    return np.sum(hedged_exposure**2)  # Sum of squared residuals

def hedge_constraint(hedge_weights):
    """Maximum total hedge capacity constraint"""
    return 1000000 - np.sum(np.abs(hedge_weights))  # $1MM cap

# Initial guess (zero hedge)
x0 = np.zeros(len(cds_returns.columns))

# Bounds: allow both long and short positions
bounds = [(-100000, 100000) for _ in range(len(cds_returns.columns))]

# Constraints
constraints = [{'type': 'ineq', 'fun': hedge_constraint}]

# Solve optimization
result = minimize(
    hedge_objective,
    x0,
    bounds=bounds,
    constraints=constraints,
    method='SLSQP'
)

optimal_hedge_weights = result.x
print("\nOptimal Hedge Notionals:")
for idx, weight in zip(cds_returns.columns, optimal_hedge_weights):
    print(f"{idx}: ${weight:,.2f}")

### Step 5: Calculate Residual Risk
def calculate_residual_risk():
    """Calculate portfolio risk before and after hedging"""
    # Portfolio dollar returns
    portfolio_dollar_returns = bond_returns.dot(cs01_values)
    
    # Hedge portfolio dollar returns
    hedge_dollar_returns = cds_returns.dot(optimal_hedge_weights)
    
    # Residual risk
    residual = portfolio_dollar_returns - hedge_dollar_returns
    
    return portfolio_dollar_returns, hedge_dollar_returns, residual

# Calculate risk metrics
portfolio_returns, hedge_returns, residual_risk = calculate_residual_risk()

print("\nRisk Metrics:")
print(f"Portfolio Std Dev: ${portfolio_returns.std():,.2f}/day")
print(f"Residual Std Dev: ${residual_risk.std():,.2f}/day")
print(f"Risk Reduction: {100*(1 - residual_risk.std()/portfolio_returns.std()):.1f}%")

### Step 6: Risk Monitoring System
def calculate_risk_metrics(residual_risk, window=30):
    """Calculate rolling risk metrics"""
    rolling_std = residual_risk.rolling(window).std()
    rolling_mean = residual_risk.rolling(window).mean()
    return rolling_std, rolling_mean

def monitor_risk(current_residual, rolling_std, rolling_mean, n_std=2):
    """Determine hedge adjustment based on current risk"""
    z_score = (current_residual - rolling_mean) / rolling_std
    
    if z_score > n_std:
        return "SELL hedge"
    elif z_score < -n_std:
        return "BUY hedge"
    else:
        return "NO ACTION"

# Calculate rolling metrics
rolling_std, rolling_mean = calculate_risk_metrics(residual_risk)

# Example monitoring for last day
current_residual = residual_risk.iloc[-1]
current_std = rolling_std.iloc[-1]
current_mean = rolling_mean.iloc[-1]

action = monitor_risk(current_residual, current_std, current_mean)
print(f"\nCurrent Residual: ${current_residual:,.2f}")
print(f"Current Z-Score: {(current_residual - current_mean)/current_std:.2f}")
print(f"Recommended Action: {action}")

### Step 7: Visualization
def plot_risk(residual_risk, rolling_std, rolling_mean):
    """Visualize residual risk and monitoring thresholds"""
    plt.figure(figsize=(12, 6))
    
    # Plot residual risk
    plt.plot(residual_risk.index, residual_risk, label='Residual Risk', alpha=0.7)
    
    # Plot rolling mean and std bands
    plt.plot(residual_risk.index, rolling_mean, 'g--', label='Rolling Mean')
    plt.fill_between(residual_risk.index, 
                    rolling_mean - 2*rolling_std, 
                    rolling_mean + 2*rolling_std, 
                    color='gray', alpha=0.2, label='±2σ Band')
    
    # Highlight action zones
    plt.axhspan(rolling_mean.iloc[-1] + 2*rolling_std.iloc[-1], 
                residual_risk.max(), 
                color='red', alpha=0.1, label='Sell Zone')
    plt.axhspan(residual_risk.min(), 
                rolling_mean.iloc[-1] - 2*rolling_std.iloc[-1], 
                color='green', alpha=0.1, label='Buy Zone')
    
    plt.title('Residual Risk Monitoring')
    plt.ylabel('Dollar Risk')
    plt.xlabel('Date')
    plt.legend()
    plt.grid(True)
    plt.show()

# Plot risk history
plot_risk(residual_risk, rolling_std, rolling_mean)



import numpy as np
import pandas as pd
import random
from collections import deque
import matplotlib.pyplot as plt
from mpl_finance import candlestick_ohlc # Note: This might be deprecated, consider `mplfinance`
import matplotlib.dates as mdates
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# Ensure reproducibility for consistent results
np.random.seed(42)
tf.random.set_seed(42)

# --- 1. Define the Trading Environment ---
class CDSTradingEnv:
    def __init__(self, data, target_index_col, initial_capital=100000, commission_rate=0.0001, spread_cost=0.0005):
        """
        Initializes the CDS Trading Environment.

        Args:
            data (pd.DataFrame): Historical data for CDS indexes with 'Date' as index
                                 and columns like 'CDX_IG', 'CDX_EM', etc.
            target_index_col (str): The name of the column in 'data' that represents the
                                    CDS index to be traded (e.g., 'CDX_IG').
            initial_capital (float): Starting capital for the agent.
            commission_rate (float): Commission per trade as a percentage of trade value.
            spread_cost (float): Represents bid-ask spread or slippage as a percentage.
        """
        if target_index_col not in data.columns:
            raise ValueError(f"'{target_index_col}' not found in data columns. Available: {data.columns.tolist()}")

        self.data = data
        self.target_index_col = target_index_col
        self.initial_capital = initial_capital
        self.capital = initial_capital
        self.commission_rate = commission_rate
        self.spread_cost = spread_cost
        self.shares = 0  # Number of CDS index units held (conceptual, represents exposure)
        
        # Use the specified target index column for price history
        self.price_history = data[target_index_col].values
        
        # Store OHLC for visualization, approximating if only Close is available
        if all(col in data.columns for col in ['Open', 'High', 'Low', 'Close']):
            self.ohlc_data = data[['Open', 'High', 'Low', 'Close']].values
        else:
            # Simple approximation for OHLC if not present
            print(f"Warning: OHLC data not found for {target_index_col}. Approximating for visualization.")
            self.ohlc_data = self._approximate_ohlc(data[target_index_col])
        
        self.current_step = 0
        self.history = [] # To store actions, capital, and position
        self.position = 0 # 0: Hold, 1: Long, -1: Short (simplified for now)

        self.window_size = 10 # Lookback window for state calculation
        self.action_space = [0, 1, 2] # 0: Hold, 1: Buy, 2: Sell (flatten long position)

        self.reset()

    def _approximate_ohlc(self, close_prices):
        """A simple way to approximate OHLC from just close prices for visualization."""
        ohlc = []
        for i in range(len(close_prices)):
            c = close_prices[i]
            o = close_prices[i-1] if i > 0 else c # Open = previous Close
            
            # Add some noise for High/Low relative to Open/Close
            # This is a very rough approximation, real OHLC is better
            change = (c - o)
            high = max(o, c) + abs(change) * 0.1 + np.random.rand() * 0.05
            low = min(o, c) - abs(change) * 0.1 - np.random.rand() * 0.05
            
            ohlc.append([o, high, low, c])
        return np.array(ohlc)

    def reset(self):
        self.capital = self.initial_capital
        self.shares = 0
        self.current_step = self.window_size # Start after enough data for initial state
        self.history = []
        self.position = 0
        return self._get_state()

    def _get_state(self):
        if self.current_step < self.window_size:
            # Pad with zeros until enough data for the window
            return np.zeros(self.window_size + 1) # +1 for position
        
        window = self.price_history[self.current_step - self.window_size : self.current_step]
        
        # Normalize the window
        if np.std(window) != 0:
            normalized_window = (window - np.mean(window)) / np.std(window)
        else:
            normalized_window = np.zeros(self.window_size)

        state = np.append(normalized_window, self.position)
        return state

    def step(self, action):
        current_price = self.price_history[self.current_step]
        reward = 0
        done = False

        self.current_step += 1
        if self.current_step >= len(self.price_history):
            done = True

        # --- Execute Action ---
        if action == 1:  # Buy
            if self.position == 0: # Only buy if currently flat
                buy_amount = self.capital / (current_price * (1 + self.commission_rate + self.spread_cost))
                if buy_amount * current_price > 0: # Ensure positive purchase
                    self.shares += buy_amount
                    self.capital -= buy_amount * current_price * (1 + self.commission_rate + self.spread_cost)
                    self.position = 1
        
        elif action == 2:  # Sell (liquidate long position)
            if self.position == 1 and self.shares > 0: # Only sell if currently long
                sale_value = self.shares * current_price * (1 - self.commission_rate - self.spread_cost)
                
                # Reward based on percentage profit/loss on the closed trade
                # A more accurate trade profit requires storing buy price. For simplicity,
                # let's use a proportional reward for closing a trade.
                # Here, a simple reward proportional to the capital change upon closing
                # is used, scaled to make it more impactful for learning.
                if self.history and self.history[-1]['position'] == 1: # If last action was a buy and we held
                    # Approximate gain/loss from this specific trade
                    entry_price = self.history[-1]['price'] # This is crude, better to track specific trades
                    trade_pnl_per_share = (current_price * (1 - self.commission_rate - self.spread_cost)) - (entry_price * (1 + self.commission_rate + self.spread_cost))
                    reward = (trade_pnl_per_share * self.shares) / self.initial_capital * 5.0 # Scale reward
                else: # If agent somehow sold without a clear prior buy (e.g. from initial capital state)
                    reward = 0 
                    
                self.capital += sale_value
                self.shares = 0
                self.position = 0
        
        # --- Calculate Next State & End of Episode Reward ---
        next_state = self._get_state()

        if done:
            final_value = self.capital + self.shares * current_price * (1 - self.commission_rate)
            reward += (final_value - self.initial_capital) / self.initial_capital * 10.0 # Scale for better signal
            
            # Penalize remaining open positions at the end (could be a loss if not liquidated)
            if self.shares != 0:
                reward -= abs(self.shares * current_price * self.spread_cost) / self.initial_capital * 5.0
            
            # Penalize if final capital is less than initial capital significantly
            if final_value < self.initial_capital * 0.95: # If lost more than 5%
                reward -= 1.0 # Significant penalty for losing money

        # Record history for backtesting visualization
        self.history.append({
            'capital': self.capital,
            'shares': self.shares,
            'position': self.position,
            'price': current_price,
            'action': action,
            'reward': reward,
            'portfolio_value': self.get_portfolio_value()
        })

        return next_state, reward, done, {}

    def get_portfolio_value(self):
        current_price = self.price_history[self.current_step-1] if self.current_step > 0 else self.price_history[0]
        return self.capital + self.shares * current_price


# --- 2. Implement the Q-Learning Agent ---
class DQNAgent:
    def __init__(self, state_size, action_size, learning_rate=0.001, gamma=0.95,
                 epsilon=1.0, epsilon_decay=0.995, epsilon_min=0.01,
                 batch_size=64, memory_size=2000):
        self.state_size = state_size
        self.action_size = action_size
        self.memory = deque(maxlen=memory_size)
        self.learning_rate = learning_rate
        self.gamma = gamma    # Discount factor for future rewards
        self.epsilon = epsilon  # Exploration-exploitation trade-off
        self.epsilon_decay = epsilon_decay
        self.epsilon_min = epsilon_min
        self.batch_size = batch_size
        self.model = self._build_model()

    def _build_model(self):
        model = Sequential()
        model.add(Dense(64, input_dim=self.state_size, activation='relu'))
        model.add(Dense(64, activation='relu'))
        model.add(Dense(self.action_size, activation='linear'))
        model.compile(loss='mse', optimizer=Adam(learning_rate=self.learning_rate))
        return model

    def remember(self, state, action, reward, next_state, done):
        self.memory.append((state, action, reward, next_state, done))

    def act(self, state):
        if np.random.rand() <= self.epsilon:
            return random.randrange(self.action_size) # Explore
        
        state_reshaped = state.reshape(1, -1) 
        act_values = self.model.predict(state_reshaped, verbose=0)
        return np.argmax(act_values[0]) # Exploit

    def replay(self):
        if len(self.memory) < self.batch_size:
            return

        minibatch = random.sample(self.memory, self.batch_size)
        states, targets = [], []
        
        for state, action, reward, next_state, done in minibatch:
            state_reshaped = state.reshape(1, -1)
            next_state_reshaped = next_state.reshape(1, -1)
            
            target = reward
            if not done:
                target = reward + self.gamma * np.amax(self.model.predict(next_state_reshaped, verbose=0)[0])
            
            current_q_values = self.model.predict(state_reshaped, verbose=0)[0]
            current_q_values[action] = target
            
            states.append(state)
            targets.append(current_q_values)
            
        self.model.fit(np.array(states), np.array(targets), epochs=1, verbose=0)
        
        if self.epsilon > self.epsilon_min:
            self.epsilon *= self.epsilon_decay

# --- 3. Training Loop ---
def train_agent(env, agent, episodes=100):
    portfolio_values = []
    
    for e in range(episodes):
        state = env.reset()
        done = False
        total_reward = 0
        
        # Adjust epsilon for training, allowing more exploration in early episodes
        # Decay epsilon only if it's not already at minimum
        if agent.epsilon > agent.epsilon_min:
            agent.epsilon *= agent.epsilon_decay
        if e == 0: # Ensure initial exploration for the very first episode
            agent.epsilon = 1.0

        while not done:
            action = agent.act(state)
            next_state, reward, done, _ = env.step(action)
            
            state_np = np.array(state)
            next_state_np = np.array(next_state)

            agent.remember(state_np, action, reward, next_state_np, done)
            state = next_state
            total_reward += reward
            
            agent.replay()
        
        final_portfolio_value = env.get_portfolio_value()
        portfolio_values.append(final_portfolio_value)
        
        print(f"Episode {e+1}/{episodes}, Final Portfolio Value: ${final_portfolio_value:,.2f}, Total Reward: {total_reward:.2f}, Epsilon: {agent.epsilon:.2f}")

    return portfolio_values

# --- 4. Load your CDS Data ---
# --- IMPORTANT: Specify the path to your CSV file ---
csv_file_path = 'cds_data.csv' 

try:
    df_cds = pd.read_csv(csv_file_path, index_col='Date', parse_dates=True)
    # Ensure columns are uppercase if they might vary
    df_cds.columns = df_cds.columns.str.upper() 
    print(f"Successfully loaded data from {csv_file_path}. Columns: {df_cds.columns.tolist()}")

    # Define the index you want to trade (e.g., 'CDX_IG', 'CDX_EM', 'ITRX_MAIN', 'ITRX_XOVER')
    TARGET_CDS_INDEX = 'CDX_IG' # <--- CHANGE THIS to the index you want to trade!

    # Create a 'Close' column from the selected target index for consistency with environment
    df_cds['Close'] = df_cds[TARGET_CDS_INDEX]

    # If you don't have OHLC, the environment will approximate it.
    # If you have them, make sure they are named 'Open', 'High', 'Low', 'Close'
    # For example, if your data has 'CDX_IG_Open', 'CDX_IG_High', etc., you'd need to rename them first:
    # df_cds['Open'] = df_cds['CDX_IG_Open']
    # df_cds['High'] = df_cds['CDX_IG_High']
    # df_cds['Low'] = df_cds['CDX_IG_Low']
    
except FileNotFoundError:
    print(f"Error: The file '{csv_file_path}' was not found.")
    print("Please ensure your CSV file is in the same directory as this script, or provide the full path.")
    print("Example CSV format:")
    print("Date,CDX_IG,CDX_EM,ITRX_Main,ITRX_XOVER")
    print("2020-01-01,100.00,200.00,50.00,300.00")
    exit() # Exit if data cannot be loaded
except KeyError as e:
    print(f"Error: Missing expected column in CSV: {e}. Please check your column names.")
    print(f"Expected columns for trading: {TARGET_CDS_INDEX}. Other columns for context: CDX_EM, ITRX_Main, ITRX_XOVER.")
    exit()

# --- 5. Run the Simulation ---
# Pass the full DataFrame and the target index column to the environment
env = CDSTradingEnv(df_cds, target_index_col=TARGET_CDS_INDEX) 
state_size = env._get_state().shape[0]
action_size = len(env.action_space)

agent = DQNAgent(state_size, action_size)

print(f"Training agent for {TARGET_CDS_INDEX} on {len(env.data)} data points...")
training_results = train_agent(env, agent, episodes=100) # You can increase episodes for more training

# --- 6. Visualization Functions ---

def plot_training_results(training_results, initial_capital, index_name):
    plt.figure(figsize=(14, 7))
    plt.plot(training_results)
    plt.title(f'Final Portfolio Value per Episode during Training ({index_name})', fontsize=16)
    plt.xlabel('Episode', fontsize=12)
    plt.ylabel('Final Portfolio Value', fontsize=12)
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')
    plt.legend()
    plt.tight_layout()
    plt.show()

def plot_backtest_results(env_history, price_data, window_size, initial_capital, index_name):
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 12), sharex=True, gridspec_kw={'height_ratios': [3, 1]})

    # --- Plot 1: Price Chart with Buy/Sell Signals ---
    # Prepare OHLC data for candlestick plot
    # The `ohlc_data` property of the environment already has the approximated OHLC
    # We need to map dates to numbers for `candlestick_ohlc`
    ohlc_for_plot = []
    # Only use the data that the environment actually processed (from window_size onward)
    for i in range(window_size, len(price_data)):
        date_num = mdates.date2num(price_data.index[i])
        ohlc_values = env.ohlc_data[i] # Get the approximated OHLC for this date
        ohlc_for_plot.append([date_num, ohlc_values[0], ohlc_values[1], ohlc_values[2], ohlc_values[3]])

    candlestick_ohlc(ax1, ohlc_for_plot, width=0.6, colorup='green', colordown='red', alpha=0.8)
    
    # Extract signals from history
    buy_signals_x, buy_signals_y = [], []
    sell_signals_x, sell_signals_y = [], []
    
    # Iterate through the environment's history, which starts after window_size
    for i, record in enumerate(env_history):
        # Calculate the actual date index in the original full dataset
        date_index = price_data.index[i + window_size] 
        price = record['price']
        action = record['action']
        
        # To identify an actual "buy" or "sell" trade, we check position change
        # A buy happens if action was 1 AND position changed from 0 to 1
        if action == 1 and (i == 0 or env_history[i-1]['position'] == 0) and record['position'] == 1:
             buy_signals_x.append(date_index)
             buy_signals_y.append(price)
        # A sell happens if action was 2 AND position changed from 1 to 0
        elif action == 2 and (i > 0 and env_history[i-1]['position'] == 1) and record['position'] == 0:
             sell_signals_x.append(date_index)
             sell_signals_y.append(price)

    ax1.scatter(buy_signals_x, buy_signals_y, marker='^', color='green', label='Buy Signal', alpha=0.9, s=150, zorder=5)
    ax1.scatter(sell_signals_x, sell_signals_y, marker='v', color='red', label='Sell Signal', alpha=0.9, s=150, zorder=5)
    
    ax1.set_title(f'{index_name} Price with Trading Signals', fontsize=16)
    ax1.set_ylabel('CDS Index Level', fontsize=12)
    ax1.grid(True, linestyle='--', alpha=0.7)
    ax1.legend()
    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))
    ax1.xaxis.set_major_locator(mdates.AutoLocator())
    fig.autofmt_xdate()

    # --- Plot 2: Portfolio Value ---
    portfolio_values = [h['portfolio_value'] for h in env_history]
    dates_for_portfolio = price_data.index[window_size:]

    ax2.plot(dates_for_portfolio, portfolio_values, label='Portfolio Value', color='blue', linewidth=2)
    ax2.axhline(y=initial_capital, color='r', linestyle='--', label='Initial Capital')
    ax2.set_title('Portfolio Value Over Time', fontsize=16)
    ax2.set_xlabel('Date', fontsize=12)
    ax2.set_ylabel('Portfolio Value', fontsize=12)
    ax2.grid(True, linestyle='--', alpha=0.7)
    ax2.legend()
    
    plt.tight_layout()
    plt.show()

# --- 7. Backtesting Module ---
def backtest_agent(env_class, agent, data_to_backtest, target_index_col):
    """
    Runs the trained agent on a given dataset and records performance.
    
    Args:
        env_class (class): The CDSTradingEnv class itself.
        agent (DQNAgent): The trained RL agent.
        data_to_backtest (pd.DataFrame): The historical data for backtesting.
        target_index_col (str): The name of the column representing the index being traded.
    
    Returns:
        float: Final portfolio value.
        list: History of the environment (for plotting).
    """
    # Create a new environment instance for backtesting to ensure clean state
    # Pass the class and then instantiate it with appropriate parameters
    backtest_env = env_class(data_to_backtest, target_index_col=target_index_col,
                             initial_capital=env.initial_capital, # Use initial capital from training env
                             commission_rate=env.commission_rate,
                             spread_cost=env.spread_cost)
    
    state = backtest_env.reset()
    done = False
    
    # Set epsilon to a very low value for backtesting (exploitation only)
    agent.epsilon = 0.00 # Set to 0 for pure exploitation, or small value for tiny exploration
    
    while not done:
        action = agent.act(state)
        next_state, reward, done, _ = backtest_env.step(action)
        state = next_state

    final_value = backtest_env.get_portfolio_value()
    print(f"\nBacktesting Complete. Final Portfolio Value: ${final_value:,.2f}")
    return final_value, backtest_env.history

# --- Execute Training, Backtesting and Visualization ---

# Plot training progress
plot_training_results(training_results, env.initial_capital, TARGET_CDS_INDEX)

# Perform backtesting on the same data for demonstration (ideally, use unseen data)
print(f"\n--- Starting Backtesting for {TARGET_CDS_INDEX} ---")
final_backtest_value, backtest_history = backtest_agent(CDSTradingEnv, agent, df_cds, TARGET_CDS_INDEX)

# Visualize backtest results
plot_backtest_results(backtest_history, df_cds, env.window_size, env.initial_capital, TARGET_CDS_INDEX)
