{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1970618-454f-40dd-8481-641b9ae94764",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (0, 1), indices imply (0, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 132\u001b[0m\n\u001b[1;32m    126\u001b[0m signals_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m: dates_all,\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m: signals_all,\n\u001b[1;32m    129\u001b[0m })\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    131\u001b[0m weights_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([w \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w)\u001b[38;5;241m==\u001b[39m\u001b[38;5;28mlen\u001b[39m(TICKERS) \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mlen\u001b[39m(TICKERS)) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m weights_all])\n\u001b[0;32m--> 132\u001b[0m weights_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(weights_array, columns\u001b[38;5;241m=\u001b[39mTICKERS, index\u001b[38;5;241m=\u001b[39mdates_all)\n\u001b[1;32m    134\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m14\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m    135\u001b[0m plt\u001b[38;5;241m.\u001b[39mstep(signals_df\u001b[38;5;241m.\u001b[39mindex, signals_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msignal\u001b[39m\u001b[38;5;124m'\u001b[39m], where\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBuy Signal (1=Buy, 0=Hold)\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m ndarray_to_mgr(\n\u001b[1;32m    828\u001b[0m             data,\n\u001b[1;32m    829\u001b[0m             index,\n\u001b[1;32m    830\u001b[0m             columns,\n\u001b[1;32m    831\u001b[0m             dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    832\u001b[0m             copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    833\u001b[0m             typ\u001b[38;5;241m=\u001b[39mmanager,\n\u001b[1;32m    834\u001b[0m         )\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m _check_values_indices_shape_match(values, index, columns)\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/myenv/lib/python3.12/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (0, 1), indices imply (0, 4)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import combinations\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# ------------------------------\n",
    "# Configuration & Sample Data\n",
    "# ------------------------------\n",
    "\n",
    "TICKERS = ['CDX IG', 'CDX HY', 'iTraxx Main', 'iTraxx Xover']\n",
    "COUPON_RATES = {'CDX IG': 100, 'CDX HY': 500, 'iTraxx Main': 100, 'iTraxx Xover': 500}\n",
    "CS01_LIMITS = {'CDX IG': 0.25, 'CDX HY': 0.10, 'iTraxx Main': 0.25, 'iTraxx Xover': 0.10}  # in millions\n",
    "NOTIONAL = 10  # in millions\n",
    "FREQ = 'D'  # Change to 'W-FRI' for weekly analytics\n",
    "\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2021-01-01', '2025-01-01', freq=FREQ)\n",
    "\n",
    "# Simulate desk PnL and CDS spreads\n",
    "desk_pnl = pd.Series(np.random.normal(0, 0.01 if FREQ == 'D' else 0.05, len(dates)), index=dates)\n",
    "cds_data = pd.DataFrame({ticker: np.random.normal(100, 10, len(dates)) for ticker in TICKERS}, index=dates)\n",
    "\n",
    "# ------------------------------\n",
    "# Utility Functions\n",
    "# ------------------------------\n",
    "\n",
    "def calculate_cs01(spread, notional=NOTIONAL, duration=5):\n",
    "    return notional * duration * 0.0001\n",
    "\n",
    "def train_pnl_model(features, target):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_signal_model(features, pnl):\n",
    "    label = (pnl > 0).astype(int)\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    model.fit(features, label)\n",
    "    return model\n",
    "\n",
    "def optimize_hedge(expected_pnl, spreads, cs01_values, cs01_limits, tickers):\n",
    "    roll_multiplier = 0.2 / 252 if FREQ == 'D' else 0.2 / 52\n",
    "    coupon_multiplier = 1/252 if FREQ == 'D' else 1/52\n",
    "\n",
    "    roll_cost = roll_multiplier * spreads.values * NOTIONAL * 0.0001\n",
    "    coupon_cost = np.array([COUPON_RATES[t] * NOTIONAL * coupon_multiplier * 0.0001 for t in tickers])\n",
    "    total_cost = roll_cost + coupon_cost\n",
    "\n",
    "    def objective(weights):\n",
    "        return -np.dot(weights, expected_pnl - total_cost)\n",
    "\n",
    "    constraints = [{'type': 'ineq', 'fun': lambda w, i=i: cs01_limits[i] - w[i] * cs01_values[i]} \n",
    "                   for i in range(len(expected_pnl))]\n",
    "    bounds = [(0, None) for _ in expected_pnl]\n",
    "    initial_guess = np.zeros(len(expected_pnl))\n",
    "\n",
    "    result = minimize(objective, initial_guess, bounds=bounds, constraints=constraints)\n",
    "    return result.x if result.success else np.zeros(len(expected_pnl))\n",
    "\n",
    "# ------------------------------\n",
    "# Strategy Execution\n",
    "# ------------------------------\n",
    "\n",
    "def run_model(desk_pnl, cds_data):\n",
    "    features = cds_data.diff().dropna()\n",
    "    desk_pnl = desk_pnl[features.index]\n",
    "    pnl_model = train_pnl_model(features, desk_pnl)\n",
    "    predicted_pnl = pd.Series(pnl_model.predict(features), index=features.index)\n",
    "\n",
    "    results = []\n",
    "    for combo in combinations(TICKERS, 2):\n",
    "        sub_features = features[list(combo)]\n",
    "        hedge_pnl = -sub_features * NOTIONAL * 0.5\n",
    "        avg_hedge_pnl = hedge_pnl.mean().values\n",
    "        latest_spreads = cds_data.iloc[-1][list(combo)]\n",
    "        cs01_vals = [calculate_cs01(latest_spreads[t]) for t in combo]\n",
    "        cs01_lims = [CS01_LIMITS[t] for t in combo]\n",
    "        weights = optimize_hedge(avg_hedge_pnl, latest_spreads, cs01_vals, cs01_lims, combo)\n",
    "\n",
    "        roll_multiplier = 0.2 / 252 if FREQ == 'D' else 0.2 / 52\n",
    "        coupon_multiplier = 1/252 if FREQ == 'D' else 1/52\n",
    "        roll_cost = roll_multiplier * latest_spreads.values * NOTIONAL * 0.0001\n",
    "        coupon_cost = np.array([COUPON_RATES[t] * NOTIONAL * coupon_multiplier * 0.0001 for t in combo])\n",
    "        total_cost = roll_cost + coupon_cost\n",
    "\n",
    "        net_pnl = predicted_pnl + hedge_pnl @ weights - (weights @ total_cost)\n",
    "        sharpe = net_pnl.mean() / net_pnl.std()\n",
    "\n",
    "        results.append({\n",
    "            'combo': combo,\n",
    "            'weights': weights,\n",
    "            'net_pnl': net_pnl,\n",
    "            'sharpe': sharpe,\n",
    "            'hedge_pnl': hedge_pnl @ weights,\n",
    "            'full_hedge_pnl': hedge_pnl\n",
    "        })\n",
    "\n",
    "    best = max(results, key=lambda x: x['sharpe'])\n",
    "    signal_model = train_signal_model(features[list(best['combo'])], best['net_pnl'])\n",
    "    predicted_signals = pd.Series(signal_model.predict(features[list(best['combo'])]), index=features.index)\n",
    "\n",
    "    return {\n",
    "        'combo': best['combo'],\n",
    "        'weights': best['weights'],\n",
    "        'net_pnl': best['net_pnl'],\n",
    "        'signals': predicted_signals,\n",
    "        'features': features[list(best['combo'])],\n",
    "        'hedge_pnl': best['hedge_pnl'],\n",
    "        'desk_pnl': desk_pnl,\n",
    "        'full_hedge_pnl': best['full_hedge_pnl']\n",
    "    }\n",
    "\n",
    "# ------------------------------\n",
    "# Visualization\n",
    "# ------------------------------\n",
    "\n",
    "def visualize_results(results):\n",
    "    combo = results['combo']\n",
    "    weights = results['weights']\n",
    "    net_pnl = results['net_pnl']\n",
    "    signals = results['signals']\n",
    "\n",
    "    hedge_notional = pd.Series(weights * NOTIONAL, index=combo)\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.plot(net_pnl.cumsum(), label='Net PnL')\n",
    "    plt.title(\"Net PnL Over Time\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Cumulative PnL (MM USD)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    signal_df = pd.DataFrame({\n",
    "        'Signal': signals.replace({1: 'BUY', 0: 'HOLD'}),\n",
    "        'Net PnL': net_pnl\n",
    "    })\n",
    "    print(signal_df.tail(10))\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(results['features'].corr(), annot=True, cmap='coolwarm')\n",
    "    plt.title(\"Feature Correlation\")\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Best Combo: {combo}\")\n",
    "    print(f\"Weights: {weights}\")\n",
    "    print(f\"Hedge Notionals (MM): {hedge_notional.to_dict()}\")\n",
    "\n",
    "# ------------------------------\n",
    "# Run All\n",
    "# ------------------------------\n",
    "\n",
    "results = run_model(desk_pnl, cds_data)\n",
    "visualize_results(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a7494d3-0371-440f-a703-23f909cb5229",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
